% Encoding: UTF-8

@Electronic{Greenfield2018,
  author   = {Greenfield, Sam},
  editor   = {Google},
  title    = {Picture what the cloud can do: How the New York Times is using Google Cloud to find untold stories in millions of archived photos},
  year     = {2018},
  date     = {2018-11-09},
  url      = {https://cloud.google.com/blog/products/ai-machine-learning/how-the-new-york-times-is-using-google-cloud-to-find-untold-stories-in-millions-of-archived-photos},
  urldate  = {2018-12-08},
  abstract = {Google Cloud has teamed up with The New York Times to help them digitize their vast photo collection. It’s making use of numerous tools within Google Cloud Platform that allow them to securely store their images, provide them with a better interface for finding photos, and find new insights even from the data locked on the backs of images.},
  comment  = {Stand van zaken - Achtergrond},
  keywords = {Google Cloud Vision},
}

@Online{MOMA2018?,
  author       = {MOMA},
  editor       = {MOMA},
  title        = {Identifying art through machine learning},
  year         = {2018?},
  url          = {https://www.moma.org/calendar/exhibitions/history/identifying-art},
  subtitle     = {A project with Google Arts \& Culture Lab},
  organization = {Museum of Modern Art},
  urldate      = {2018-12-08},
  abstract     = {Given years of experience and some diligent research, identifying each work of art in an old exhibition photo doesn’t sound so hard, does it? Now imagine you have tens of thousands of photos, dating back to 1929. MoMA’s Digital Media team and Google Arts & Culture Lab set out to face this daunting challenge—or at least get a head start—using machine learning and computer vision technology.},
  comment      = {stand van zaken - achtergrond},
  keywords     = {MOMA, Google Cloud Vision, Google Arts & Culture Lab},
}

@Report{Blessings2013,
  author      = {Blessings, Alexander and Wen, Kai},
  title       = {Using Machine Learning for Identification of Art Paintings},
  type        = {resreport},
  institution = {Stanford University},
  year        = {2013},
  pagetotal   = {5},
  abstract    = {Machine learning applications have been suggested for many tasks. We have investigated the suitability of applying machine learning to the problem of art identification, which we believe to be a new, but promising field.  Our approach focuses  on  classifying  works  of  seven  different  artists,  by using a multi-class SVM with state-of-the-art features. Our results indicate that machine learning has good potential to classify art works. We conclude this paper by analyzing our results.},
  comment     = {nog lezen},
  file        = {:Blessings2013.pdf:PDF},
  keywords    = {paintings},
}

@Misc{Wevers2018,
  author     = {Wevers, Melvin and Smits, Thomas},
  title      = {Seeing History: The Visual Side of the Digital Turn},
  year       = {2018},
  abstract   = {How can computers help us to explore and analyze large collection of historical visual material},
  comment    = {stand van zaken - achtergrond},
  eventdate  = {2018-12-09},
  eventtitle = {Digital Humanities Benelux Amsterdam 2018},
  file       = {:Wevers2018.pdf:PDF},
  keywords   = {kranten, datasets, logaritmes},
}

@Misc{Wevers2018a,
  author       = {Wevers, Melvin and Smits, Thomas},
  title        = {Seeing history: analyzing large-scale historical visual datasets using deep neural networks},
  year         = {2018},
  organization = {DHLAB, KNAW},
  abstract     = {Scholars  are  increasingly  applying  computational  methods  to  analyze  the  visual  aspects  of large scale  digitized  visual  datasets Inspiring  examples  are  the  work  of  Seguin on  visual pattern discovery in large databases of paintings and Moretti’s and Impett’s large scale analysis of  body  postures  in  Aby  Warburg’s  Atlas  Mnemosyne. In  our  paper,  we  will  present  two datasets  of  historical  images  and  accompanying  metadata harvested  from  Dutch  digitized newspapers  and  reflect  on  ways  to improve  existing  neural  networks for  historical  research.  We will discuss how large historical visual datasets can be used for historical research using neural  networks.  We  will  do  this  by  describing  two  case  studies,  and  will  end  our  paper  by arguing for the need for a benchmarked dataset with historical visual material.},
  file         = {:Wevers2018a.pdf:PDF},
  keywords     = {visual dataset, logaritmes},
}

@Report{Mensink2014,
  author      = {Mensink, Thomas and van Gemert, Jan},
  title       = {The Rijksmuseum Challenge: Museum-Centered Visual Recognition},
  type        = {resreport},
  institution = {ISLA Lab - Informatics Institute University of Amsterdam},
  year        = {2014},
  pagetotal   = {4},
  abstract    = {This  paper  offers  a  challenge  for  visual  classification  and content-based retrieval of artistic content.  The challenge is posed from a museum-centric point of view offering a wide
range of object types including paintings, photographs, ceramics, furniture, etc.  The freely available dataset consists of  112,039 photographic  reproductions  of  the  artworks  exhibited in the Rijksmuseum in Amsterdam, the Netherlands. We  offer  four  automatic  visual  recognition  challenges  consisting of predicting the artist, type, material and creation year.  We include a set of baseline results, and make available state-of-the-art image features encoded with the Fishervector.   Progress on this challenge improves the tools of a museum curator while improving content-based exploration by online visitors of the museum collection.},
  comment     = {stand van zaken - achtergrond},
  file        = {:Mensink2014.pdf:PDF},
  keywords    = {Rijksmuseum dataset, theoretische studie},
}

@Online{UniAntwerpen2017?,
  editor   = {{Universiteit Antwerpen}},
  title    = {INSIGHT},
  year     = {2017?},
  url      = {http://uahost.uantwerpen.be/insight/index.php/about/},
  urldate  = {2018-12-08},
  abstract = {INSIGHT is a research project that targets the digital assets of two museum clusters in Brussels: Royal Museums of Fine Arts of Belgium and Royal Museums of Art and History. This project aims to deploy the recent advances in Artificial Intelligence (language technology and computer vision in particular) to support the enrichment of these collections with descriptive metadata. An important focus of this project is the issue of transferring knowledge from open collections, such as The Rijksmuseum Dataset, to other players in the field. To this end, we investigate issues relating to multimodality or the way in which we can simultaneously model different information streams about digital heritage objects (e.g. in different languages, or across different media). Apart from multimodality, multilinguality will be another crucial aspect of our research, which is of course important in the context of federal heritage collections in Belgium. The end goal of this project is to develop and release a series of practical Machine Learning tools for managing digital collections. A major outcome of this project will be an export of the digital collections involved as a “Europeana-ready” linked open data set, which will contribute to the broader accessibility of these collections.},
  comment  = {stand van zaken},
}

@Report{Sabatelli2018,
  author      = {Sabatelli, Matthia and Kestemont, Mike and Daelemans, Walter and Geurts, Pierre},
  title       = {Deep Transfer Learning for Art Classification Problems},
  type        = {resreport},
  institution = {Universiteit Antwerpen and Université de Liège},
  year        = {2018},
  pagetotal   = {16},
  abstract    = {In this paper we investigate whether Deep Convolutional Neural Net- works (DCNNs), which have obtained state of the art results on the ImageNet challenge, are able to perform equally well on three different art classification problems. In particular, we assess whether it is beneficial to fine tune the net- works instead of just using them as off the shelf feature extractors for a sepa- rately trained softmax classifier. Our experiments show how the first approach yields significantly better results and allows the DCNNs to develop new selective attention mechanisms over the images, which provide powerful insights about which pixel regions allow the networks successfully tackle the proposed classi- fication challenges. Furthermore, we also show how DCNNs, which have been fine tuned on a large artistic collection, outperform the same architectures which are pre-trained on the ImageNet dataset only, when it comes to the classification of heritage objects from a different dataset.},
  file        = {:Sabatelli2018.pdf:PDF},
  keywords    = {theoretische studie, logaritmes, visual datasets, Deep Convolutional Neural Networks, Art Classification, Transfer Learning, Visual Attention},
}

@Manual{AKE2014,
  editor   = {{Agentschap Kunsten en Ergoed}},
  title    = {Handleiding bij het Cultureel-Erfgoeddecreet},
  year     = {2014},
  subtitle = {Het Kwaliteitslabel},
  abstract = {Met het toekennen van een kwaliteitslabel aan collectiebeherende cultureel-erfgoedorganisaties wil de Vlaamse Gemeenschap de kwaliteitsvolle werking van deze organisaties erkennen. Het doel van het kwaliteitslabel is het zichtbaar maken, het bewaken en het verbeteren van de kwaliteit van de werking van collectiebeherende cultureel-erfgoedorganisaties in Vlaanderen. De Vlaamse Gemeenschap kent kwaliteitslabels toe aan musea, culturele archiefinstellingen en erfgoedbibliotheken. Om een kwaliteitslabel te krijgen moet de collectiebeherende cultureel-erfgoedorganisatie aan minimale kwaliteitsnormen voldoen. Deze kwaliteitsnormen zitten vervat in de voorwaarden voor de toekenning van het kwaliteitslabel. },
}

@Misc{Gatz2014,
  author       = {Gatz, Sven},
  editor       = {Vlaams Minister van Cultuur, Jeugd en Media},
  title        = {Beleidsnota Cultuur 2014-2019},
  year         = {2014},
  date         = {2014-10},
  organization = {De Vlaamse Regering},
  file         = {:Gatz2014.pdf:PDF},
  keywords     = {cultuurbeleid},
}

@Misc{Gatz2016,
  author       = {Gatz, Sven},
  title        = {Conceptnota aan de Vlaamse Regering. Naar een duurzame cultureel-erfgoedwerking in Vlaanderen.},
  year         = {2016},
  date         = {2016-03},
  subtitle     = {Een langetermijnvisie voor cultureel erfgoed en cultureel-erfgoedwerking in Vlaanderen},
  organization = {Vlaamse Regering},
  keywords     = {cultuurbeleid},
}

@Misc{JeugdMediaC2018,
  author       = {{Departement Cultuur, Jeugd en Media}},
  editor       = {{Departement Cultuur, Jeugd en Media}},
  title        = {Visienota: Een Vlaams cultuurbeleid in het digitale tijdperk},
  year         = {2018},
  date         = {2018-06},
  organization = {Vlaamse Regering},
  file         = {:JeugdMediaC2018.pdf:PDF},
  keywords     = {cultuurbeleid},
}

@Online{JeugdMediaC2018a,
  author   = {{Departement Cultuur, Jeugd en Media}},
  editor   = {{Departement Cultuur, Jeugd en Media}},
  title    = {Inhaalbeweging voor digitale collectieregistratie},
  year     = {2018},
  date     = {2018-07-12},
  url      = {http://www.kunstenenerfgoed.be/nl/nieuws/inhaalbeweging-voor-digitale-collectieregistratie},
  urldate  = {2018-12-08},
  abstract = {De Vlaamse minister van Cultuur heeft zich tot doel gesteld om de achterstanden op het vlak van collectieregistratie binnen de cultureel-erfgoedsector weg te werken. Met een nieuw subsidiereglement voor digitale collectieregistratie wil de minister de eerste stappen zetten om hier concreet werk van te maken.},
}

@Manual{JeugdMediaC2018b,
  editor   = {{Departement Cultuur, Jeugd en Media}},
  title    = {Subsidies voor inhaalbeweging digitale collectieregistratie bij collectiebeherende cultureel-erfgoedorganisaties},
  year     = {2018},
  date     = {2018-07-09},
  subtitle = {Reglement},
  file     = {:JeugdMediaC2018b.pdf:PDF},
  keywords = {cultuurbeleid},
}

@Online{Nasjonalmuseet2017?,
  author   = {Nasjonalmuseet},
  editor   = {{Nasjonalmuseet}},
  title    = {Project: "Principal Components"},
  year     = {2017?},
  url      = {http://www.nasjonalmuseet.no/en/collections_and_research/collection_management/digital_collection_management/Project%3A+%C2%ABPrincipal+Components%C2%BB.b7C_wJjU4L.ips},
  urldate  = {2018-12-08},
  abstract = {In this project, we have tried out artificial intelligence in principal component analysis on our images, by using neural networks and algorithms.

Two of the results in the project are described in more detail below.

The algorithms that show compositional similarities for us in a new user interface on our website.
The algorithm that classifies the National Museum's art by subject keywords.},
  keywords = {Iconclass, Caffe, gelijkenissen, gezichten, kleuren},
}

@Online{Westvang2017?,
  author   = {Westvang, Even},
  title    = {Principal Components},
  year     = {2017?},
  url      = {http://bengler.no/principalcomponents},
  subtitle = {Machine learning in search of the uncanny},
  urldate  = {2018-12-08},
  abstract = {Following on the Repcol project, Principal Components looks at applying a diverse set of machine learning technologies to museum collections. It looks at how machine learning can give easier access to collections through better metadata and explorative interfaces. Concurrently it also explores the strange and uncanny artifacts and errors that arise from machine learning processes and errors.},
  keywords = {Nasjonaalmuseet, Caffe, classificeren},
}

@Online{Smith2017,
  author   = {Smith, Ryan P.},
  title    = {How Artificial Intelligence Could Revolutionize Archival Museum Research},
  year     = {2017},
  date     = {2017-11-03},
  url      = {https://www.smithsonianmag.com/smithsonian-institution/how-artificial-intelligence-could-revolutionize-museum-research-180967065/},
  urldate  = {2018-12-08},
  abstract = {When you think of artificial intelligence, the field of botany probably isn't uppermost in your mind. When you picture settings for cutting-edge computational research, century-old museums may not top the list. And yet, a just-published article in the Biodiversity Data Journal shows that some of the most exciting and portentous innovation in machine learning is taking place at none other than the National Herbarium of the National Museum of Natural History in Washington, D.C.},
  keywords = {planten, deep learning},
}

@Online{Hindle2017,
  author   = {Hindle, Adrian},
  title    = {Automated image analysis with IIIF},
  year     = {2017},
  date     = {2017-06-20},
  url      = {https://blog.cogapp.com/automated-image-analysis-with-iiif-6594ff5b2b32},
  subtitle = {Using Artificial Intelligence for bulk image analysis},
  urldate  = {2018-12-08},
  abstract = {In this article we’ll show how to use the IIIF Presentation and Image APIs to gather inputs including:

    Finding interesting images
    Image recognition and automatic tagging
    Colour analysis
    Finding similar images
    Term extraction
    The best image analysis API

And we will show the interesting, valuable, and occasionally hilarious outcomes from these techniques for bulk image analysis.},
  keywords = {IIIF, VRS},
}

@Misc{Roddis2018,
  author     = {Roddis, Tristan},
  title      = {When automated analysis goes wrong},
  year       = {2018},
  date       = {2018-05-16},
  url        = {https://www.slideshare.net/Europeana/when-automated-analysis-goes-wrong-by-tristan-roddis-europeanatech-conference-2018},
  urldate    = {2018-12-08},
  eventtitle = {EuropeanaTech Conference 2018},
  keywords   = {IIIF, VRS, fouten},
}

@Online{Fraser2018,
  author   = {Fraser, Matt},
  title    = {Using Google Cloud AutoML to classify poisonous Australian spiders},
  year     = {2018},
  date     = {2018-03-14},
  url      = {https://shinesolutions.com/2018/03/14/using-google-cloud-automl-vision-to-classify-poisonous-australian-spiders/},
  urldate  = {2018-12-09},
  keywords = {google cloud vision},
}

@Online{Lardinois2018,
  author  = {Lardinois, Frederic},
  editor  = {TechCrunch},
  title   = {Google’s AutoML lets you train custom machine learning models without having to code},
  year    = {2018},
  url     = {https://techcrunch.com/2018/01/17/googles-automl-lets-you-train-custom-machine-learning-models-without-having-to-code},
  urldate = {2018-12-09},
}

@Online{Oberoi2016,
  author  = {Oberoi, Gaurav},
  title   = {Comparing the Top Five Computer Vision APIs},
  year    = {2016},
  date    = {2016-07-11},
  url     = {https://goberoi.com/comparing-the-top-five-computer-vision-apis-98e3e3d7c647},
  urldate = {2018-12-09},
}

@Online{Wiericx2011,
  author = {Wiericx, Bram},
  title  = {Crowdsourcing in het Huis van Alijn},
  year   = {2011},
  date   = {2011-08-09},
  url    = {https://faro.be/blogs/bram-wiercx/crowdsourcing-in-het-huis-van-alijn},
}

@Collection{Bordoni2016,
  editor = {Bordoni, Luciana and Mele, Francesco and Sorgente, Antonio},
  title  = {Artificial Intelligence for Cultural Heritage},
  year   = {2016},
}

@TechReport{Caimotti2017,
  author      = {Caimotti, Emanuele and Montagnuolo, Maurizio and Messina, Alberto},
  title       = {An Efficient Visual Search Engine for Cultural Broadcast Archives},
  institution = {Politecnico di Torino and RAI Radiotelevisione Italiana},
  year        = {2017},
  type        = {resreport},
  urldate     = {2019-03-05},
  file        = {:Caimotti2017 - An Efficient Visual Search Engine for Cultural Broadcast Archives.pdf:PDF},
}

@Proceedings{Mele2017,
  title     = {Proceedings of the AI*CH 2017},
  year      = {2017},
  date      = {2017-11-14},
  editor    = {Mele, Francesco and Origlia, Antonio and Sorgente, Antionio},
  subtitle  = {The 11th workshop onArtificial Intelligence for Cultural Heritage},
  eventdate = {2017-11-14},
  url       = {http://smcm.isasi.cnr.it/AIxCH2017/wp-content/uploads/2017/12/Proceedings_AIxCH2017.pdf},
  urldate   = {2019-03-05},
  file      = {:Mele2017 - Proceedings of TheAI_CH 2017.pdf:PDF},
}

@WWW{Gong2017,
  author       = {Gong, Kevin},
  title        = {Best Practices for Custom Models in Watson Visual Recognition},
  year         = {2017},
  date         = {2017-11-13},
  url          = {https://medium.com/ibm-watson/best-practices-for-custom-classifiers-in-watson-visual-recognition-1015a273f75d},
  organization = {IBM Watson},
  urldate      = {2019-03-05},
  abstract     = {trainingsbeelden moet overeenkomen met de beelden die je wil laten analyseren. Duidelijke visuele verschillen tussen trainingsbeelden en testbeelden zorgen voor slechte resulaten.

factoren:
- resolutie
- belichting
- hoek
- focus
- kleur
- vorm
- afstand tot onderwerp
- aanwezigheid van andere objecten

ideaal: 100+ beelden per concept

waar hebben visuele API's het moeilijk mee:
- herkennen van mensen (face recognition)
- details detecteren --> beter dan om het beeld op te breken in stukjes of om in te zoomen op de relevante onderdelen
- classificatie van emoties },
  keywords     = {training},
  timestamp    = {2019-03-05},
}

@TechReport{Elhassouny2017,
  author      = {Elhassouny, Azeddine and Tam, Le Nhan and Sayed, Dina and Steffens, Bjoern and Sri, Lak},
  title       = {Building Cognitive Applications with IBM Watson Services: Volume 3 Visual Recognition},
  institution = {IBM Redbooks},
  year        = {2017},
  type        = {techreport},
  file        = {:Elhassouny2017 - Building Cognitive Applications with IBM Watson Services_ Volume 3 Visual Recognition.pdf:PDF},
  timestamp   = {2019-03-08},
}

@WWW{Lih2019,
  author       = {Lih, Andrew},
  title        = {Combining AI and Human Judgment to Build Knowledge about Art on a Global Scale},
  year         = {2019},
  date         = {2019-03-04},
  url          = {https://www.metmuseum.org/blogs/now-at-the-met/2019/wikipedia-art-and-ai},
  organization = {The Metropolitan Museum of Art},
  abstract     = {200 vrijwilligers (jongeren, kusthistorici, technologists, ...) kwamen samen in het MET om kunstwerken te classificeren. Dit om een AI systeem te ondersteunen. Metadata werd verzameld op Wikidata om zo de beschrijvende metadata beschikbaar te maken.

Nut? Musea bewaren metadata van hun collectie (beschrijvende, locatie, provenance...) Deze metadata zijn niet gestandaardiseerd.

In 2018 starte MET met een subject-keyword tagging project.  --> consistente beschrijvende metadata creëren die beschikbaar is voor iedereen onder een open licentie. In een Hackaton werd er gezocht naar het gebruik van AI hiervoor --> prototypes ontwikkelen.

Kunnen de keywords gebruikt worden om een ML model te trainen that accuraat tags kon voorspellen voor kunstwerken. 

METs subject keywords werden geconnecteerd met Wikidata en beelden werden geprocessed. Goede resultaten op het vlak van landschapsachtige schilderijen (bomen, bergen, dieren). Daarna een soort van spel om feedback te geven aan de software.

Integratie met Wikidata omdat het een semantische databank is. als je zoekt naar zoogdier krijg je zowel honden, katten etc. + multilangual.},
  timestamp    = {2019-03-10},
}

@WWW{MMA2017,
  editor    = {{The Metropolitan Museum of Art}},
  title     = {The Tagging Initiative},
  year      = {2017},
  url       = {https://www.metmuseum.org/about-the-met/policies-and-documents/open-access/tagging-initiative},
  abstract  = {het onderwerp van ieder kunstwerk wordt geïdentificeerd en er wordt een tag voor ieder kunstwerk gemaakt.
==> op deze manier worden de kunstwerken ontsloten voor het brede publiek en zijn ze beter doorzoekbaar.

onderwerpen zij beschikbaar onder CC0 licentie en downloadbaar via een CSV en beschikbaar voa de MET Collection API. Deze dataset bevat common woorden die informatie geven over het onderwerp van het kunstwerk en die het zoeksystemen eenvoudiger maken om content op te halen: titel, kunstenaar, medium, nationaliteit, etc.},
  timestamp = {2019-03-10},
}

@WWW{MMA2019,
  editor    = {{The Metropolitan Museum of Art}},
  title     = {The Met x Microsoft x MIT},
  year      = {2019},
  url       = {https://www.metmuseum.org/about-the-met/policies-and-documents/open-access/met-microsoft-mit},
  abstract  = {MET, Microsoft ne MIT werkten samen in een hackathon om te zien hoe AI kon helpen om mensen met kunst te connecteren. Hiervoor werden de beelden, data en keyword dataset gerbuikt. 
Doel: Inbeelden en ontwikkelen van nieuwe schaalbare manieren om het wereldwijde publiek de meest bekende kunstcollectie te laten ontdekken, leren en ermee te creëren via AI.

Microsoft - ingenieurs en Gebruikte technologie: voorgebouwde API's zoals Azure Cognitive Services, conversational AI en Azure Machine Learning. 
MIT - studenten van MIT Open Learning en the Knowledge Futures Group
MET - curatorial staff, digital staff en researchters

Prototypes:

* Artwork of the Day: maakt gebruik van Microsoft AI om een kunstwerk te vinden die past met vandaag. een kunstwerk dat relevant is met de context van wereldgebeurtenissen en met je huidige omstandigheden. presoonlijk, geen een persoon zal hetzelfde kunstwerk op dezelfde dag krijgen. door er een API van te maken, kan je het ook integreren in alarm clocks, frigo's, etc.

* Gen Studio, maakt ook gebruik van Microsoft AI om je visueel en creatief te laten navigeren door de shared features en dimensies van the MET's Open Access collection. Een tapijt van ervaringen gebaseerd op gesofisticeerde generatieve adversarial netwerks (GAN) om zo de collectie te ontdekken. Kunstenwerken worden op nieuwe manieren met elkaar gecombineerd gebaseerd op stijlen, materialen en vormen in de MET collectie en ongekende kunstwerken ontdekken die dezelfde visuele karakteristieken delen. Een immersieve visuele ervaring. We envision Gen Studio becoming a far-reaching platform that develops appreciation of the immense historical depth and scale of The Met collection, and which identifies new perspectives on the visual relationships between cultures and the production of individual artworks.

* My Life, My Met: maakt gebruik van AI om je instagram feed in een kunstwerk om te zetten. Het gebruikt Microsoft AI om je posts op instagram te analyseren te te vervangen door het closest matching beeld uit de open access artworks van de MET collection. Zo wordt kunstwerk gebracht in dagelijkse interacties van je leven.

* Storyteller: maakt gebruik van Microsoft AI om een kunstwerken te kiezen uit de MET collection die de verhalen illustreren die je zou willen vertellen. Hiervoor maakt het gebruik van voice recognition AI om de discussie te volgen en kunstwerken te delen die passen bij de verhalen die verteld worden. 

* Tag, That's It!: combinatie van mensen en machines om zo de toegankelijkheid van de MET collection te verhogen voor de miljoenen mensen op de Wikimedia platformen. Een vorm van crowdsourcing waarbij de keywords die gegenereerd worden door het AI model gefinetuned kunnen worden.  Het AI model kan zo verbeterd worden en kan toegepast worden op iedere museumcollectie.
},
  timestamp = {2019-03-10},
}

@WWW{Tallon2019,
  author    = {Tallon, Loic},
  editor    = {{The Metropolitan Museum of Art}},
  title     = {Sparking Global Connections to Art through Open Data and Artificial Intelligence},
  year      = {2019},
  date      = {2019-02-04},
  url       = {https://www.metmuseum.org/blogs/now-at-the-met/2019/met-microsoft-mit-art-open-data-artificial-intelligence},
  abstract  = {Ambitie: MET collectie moet de meest toegankelijke, zichtbare en bruikbare collectie zijn op het internet. Educatie en disseminatie en kennis geven over de collectie buiten het fysieke. Daarom werden high res beelden en metadata van kunstwerken vrijgegeven onder een public domain CreatIve Commons Zero licentie. 

Resultaten:
- gebruik van third party platforms om de toegang tot de collectie te verhogen
- ook de reach op Wikimedia werd verviervoudigd
- nieuwe manieren om de collectie te begrijpen
- duurzame dateintegraties met andere websites
- inspiratie voor nieuwe kunstvormen
- zowel stijging van downloads en pageviews van de collectie op de Met's website
- gelijkaardige programma's werden gelanceerd door andere musea

Keyword dataset:
- ontworpen op de collectie. beantwoord de vraag "wat zie je?", bv. mannen, vrouwen, portretten, bloemen, dansen
- deze keywords kunnen gebruikt worden om te leren hoe een onderwerp weergegeven wordt doorheen periodes en culturen.
- deze keywords hebben ervoor gezorgd dat de kunstwerken op een andere manier geanalyseerd kunnen worden --> kunnen gebruikt worden als trainingdata.
--> MET x Microsoft x MIT
- bieden een zicht op hoe AI gebruikt kan worden om kunst tot bij het publiek te brengen.

Volgende stappen:
- subject dataset wordt geïntegreerd in de museumwebsite om de browsing ervaring het publiek te verbeteren en mogelijkheid te geven om de filteren op keyword
- AI introduceren van prototype tot product
- integratie met Wikidata via een SDC project.

},
  timestamp = {2019-03-10},
}

@WWW{nullN2018,
  editor    = {{The New School}},
  title     = {Parsons MS Data Viz Partners with The Met to Visualize Their Digital Collection},
  year      = {2018},
  date      = {2018-10-25},
  url       = {https://blogs.newschool.edu/news/2018/10/parsons-ms-data-viz-partners-with-the-met-to-visualize-their-digital-collection/},
  abstract  = {Met: kunst van over 5000 jaar en 470.000 objecten online en 406.000 publieke domein beelden.

Door het Open Access programma kunnen ook andere mensen gebruik maken van de collectie, wat de Parsons School of Design gedaan heeft. Studenten hebben visualisaties gedaan met de dataset.},
  timestamp = {2019-03-10},
}

@WWW{Vu2018,
  author    = {Vu, Kevin},
  title     = {Beginner’s Guide: Image Recognition And Deep Learning},
  year      = {2018},
  date      = {2018-11-29},
  url       = {https://dzone.com/articles/beginners-guide-image-recognition-and-deep-learnin},
  abstract  = {Deep learning en neural networks: algoritmes die slimmer worden in verloop van tijd.
deep learning is een geavanceerd veld in ML en het hedendaagse wonder van AI. 

ML: de computer krijgt input en op basis daarvan doet het voorspellingen. Bij deep learning gaat het anders te werk en heeft het te maken met de tijd die het krijgt. 

neurale netwerken gebruiken algoritmes die in lagen naast elkaar liggen. Ieder algoritme is daarom afhankelijk van de resultaten van de omliggende algoritmes. het probeert een proces te creëren dat overeenkomt met de manier waarop mensen redeneren. in het geval van image recognition spreekt met van convolutional neural networks. 

CNN: beelden worden opgedeeld in nummers. Wanneer we iets in het echt zien, dan geven ons hersenen het zin door het te labelen, voorspellen en het herkennen van specifieke patronen. Bij CNN doet men dat ook, maar dan met nummers. Convolution bestaat uit het gebruiken van twee functies die een derde functie opleveren. een CNN merget verschillende sets van informatie saemn en poolt die samen om zo een accurate representatie van een beeld te verkrijgen. Daarna wordt het beld beschreven in verschillende data die doior een neuraal netwerk gebruikt kan worden om een voorspelling te doen over wat het is. Computers kunnen dan die voorspelling gebruiken voor andere applicaties. 

Een neuraal netwerk leert over de tijd heen of de voorspellingen accuraat zijn. 

Er gaat veel menselijk werk in om een AI goed te krijgen. Het is vooral belangrijk om een goede dataset te hebben. De dataset wordt gebruikt om te trainen om dan het model in te zetten in het wild. Er zijn goed ontwikkelde datasets, bv. ImageNet. Dit bestaat uit 3.2 miljoen gelabelde beelden. Deze dataset kunnen door AI modellen gebruikt worden om op te oefenen.

ImageNet werd opgevolgd door AlexNet, dat een CNN architectuur gebruikte dat nog steeds in gebruik is.},
  timestamp = {2019-03-10},
}

@WWW{Raval2017,
  author = {Raval, Siraj},
  title  = {YOLO Object Detection (TensorFlow tutorial)},
  year   = {2017},
  date   = {2017-11-15},
  url    = {https://youtu.be/4eIBisqx9_g},
}

@WWW{Olafenwa2018,
  author = {Olafenwa, Moses},
  title  = {Object Detection with 10 lines of code},
  year   = {2018},
  date   = {2018-06-16},
  url    = {https://towardsdatascience.com/object-detection-with-10-lines-of-code-d6cb4d86f606},
}

@Misc{darknet13,
  author       = {Redmon, Joseph},
  title        = {Darknet: Open Source Neural Networks in C},
  year         = {2013-2016},
  howpublished = {\url{http://pjreddie.com/darknet}},
}

@Comment{jabref-meta: databaseType:biblatex;}
