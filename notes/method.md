# Gevolgde methode

## 1. Zorg dat de beelden beschikbaar zijn via een publieke URL

De beelden werden ontvangen op een harde schijf en waren niet beschikbaar via een URL. Om op een geautomatiseerde manier de API van Clarifai te kunnen bevragen, was het nodig om voor de beelden een publieke URL te voorzien.

De ontvangen beelden waren hogeresolutiebeelden en waren daarom redelijk zwaar (10 à 13 MB voor een groot deel van de beelden). Bovendien waren het veelal .tif-bestanden die je niet in de browser kunt bekijken. Als gevolg daarvan werd er gekozen om met de beeldenserver Cantaloupe te werken. Dit is een IIIF beeldenserver waarbij je beelden kan opvragen op basis van een URL via het IIIF Image API en waarbij je zowel, het formaat (.jpg in dit geval) als de gewenste grootte, rotatie, etc. kan bepalen op basis van een URL (bv. het beeld FO-10-00089 in volldige grootte opvragen, gebeurt met de URL <http://ec2-18-191-252-182.us-east-2.compute.amazonaws.com:8182/iiif/2/FO-10-00089/full/full/0/default.jpg>; om een grootte van 80% op te vragen, wordt volgende URL gebruikt: <http://ec2-18-191-252-182.us-east-2.compute.amazonaws.com:8182/iiif/2/FO-10-00089/full/pct:80/0/default.jpg>) We kozen voor deze opstelling omdat we hier ervaring mee hebben via de stageplaats, maar ook omdat op deze manier het beeld zowel in zijn volledige grootte opgevraagd kon worden (in jpg-formaat), als in een kleiner formaat, bv. wanneer het originele bestand te zwaar was. Clarifai kan beelden van max. 4MB processen. Dit bleek uiteindelijk slechts voor twee beelden nodig te zijn. Deze werden opgevraagd met een grootte van 80%.

Het nadeel aan Cantaloupe is dat beelden een tiled en multiresolutie bestandsformaat moeten hebben, zoals JPEG2000 of Pyramidal TIFF. Door onze ervaring met Cantaloupe hadden we reeds eerdre een shell script om beelden te converteren naar Pyramidal TIFF gemaakt. De command line tool ImageMagick werd gebruikt om beelden te converteren: [tif_to_pyramid.sh](../research/scripts/tif_to_pyramid.sh)

Vervolgens werden de beelden opgeladen in een Amazon AWS EC2 Ubuntu instance waar ook Cantaloupe op geïnstalleerd was. We beschikten nu voor ieder beeld over een publieke URL die gebruikt kon worden bij calls naar de Clarifai API.

## 2. Plaats alle informatie van de beelden in een CSV

Van Huis van Alijn hadden we enkel beelden ontvangen die per thema in een mapje zaten. In functie van de scripts om de Clarifai API te gebruiken, leek het nuttig om de bestandsnamen van de beelden en bijhorende metadata in een CSV te hebben. Er werd per beeld metadata toegevoegd zoals het thema (het mapje waarin de beelden zaten), het decennium (dit konden we vinden in de bestandsnaam) en het oorspronkelijke medium van het beeldbestand (ook te vinden in de bestandsnaam, zie [informatie over de dataset](dataset.md)).

Er werd een CSV gecreerd met volgende velden: base (URL), bestandsnaam, extensie, type (foto of diapositief), thema en periode (decennium). De CSV werd gecreëerd via een shell script: [create_csv.sh](../research/scripts/create_csv.sh). Om snelle opzoekingen te doen over de testset, werd de CSV ook ingeladen in een MySQL-databank. Ook hiervoor werd een script geschreven, deze keer in SQL: [import_HvA_in_database.sql](../research/scripts/import_HvA_in_database.sql).

## 3. Gebruik de CSV om de Clarifai API aan te roepen

Nu dat alle nodige gegevens in een CSV staan, kan de API van Clarifai aangeroepen worden via een script. Clarifai beschikt over API clients in verschillende programmeertalen (Java, Python, Javascript, C#, Objective-C en PHP), maar doordat we zelf het meeste voeling hebben met shell scripting, kozen we ervoor om rechtstreeks de REST API te bevragen via `curl`. De learning curve zou hier kleiner zijn. Het is voor de proefopstelling ook niet nodig om een grafische interface te hebben - enkel de responses van de API zijn belangrijk - waardoor shell scripts voldoende zijn voor de opstelling.

Een account bij Clarifai werd aangemaakt en een API key werd aangevraagd.Het general model van Clarifai werd gebruikt voor de volledige testset. Dit is het meest uitgebreide model: het bevat meer dan 11.000 verschillende concepten waaronder objecten, thema's, emoties in verschillende talen, waaronder het Nederlands. Dit model kan gebruikt worden voor een reeks van zeer uiteenlopende beelden. (voor meer info, zie [Clarfai General](https://www.clarifai.com/models/general-image-recognition-model-aaa03c23b3724a16a56b629203edc62c)).

Om de API te bevragen, werd een shell script geschreven: [predict_image.sh](../research/scripts/predict_image.sh). Het bevragen van de API verliep vlot. Gemiddeld waren er per beeld 2 à 3 seconden nodig om het te processen. Drie beelden bleken een te grote bestandsgrootte te hebben voor Clarifai. Daarom werd een nieuw script geschreven waarin de gewenste grootte en de bestandsnaam van de beelden als parameter kan meegegeven worden: [predict_image_by_size_id.sh](../research/scripts/predict_image_by_size_id.sh). Er werd gekozen om alles zoveel mogelijk in een script te zetten in functie van hergebruik.

Doordat het zo vlot verliep, werd beslist om twee nieuwe sets te maken op basis van de bestaande dataset. Er werd twee nieuwe CSV's gemaakt: 1 voor beelden over huwelijk en 1 voor beelden over vakantie. MySQL Workbench werd gebruikt om de databank met de beelden te bevragen en een export te doen in CSV. We gebruikten deze CSV's om twee andere modellen van Clarifai te bevragen: het [wedding model](https://www.clarifai.com/models/wedding-image-recognition-model-c386b7a870114f4a87477c0824499348) (voor de huwelijksbeelden) en het [travel model](https://www.clarifai.com/models/travel-image-recognition-model-eee28c313d69466f836ab83287a54ed9) (voor de vakantiebeelden). De twee bovenstaande scripts werden aangepast zodat ook het ID van de modellen als parameters met de scripts kunnen meegegeven worden (het is dus niet nodig om per model een nieuw script te schrijven of om telkens het script aan te passen zodat het juiste model bevraagd wordt).

## 4. Plaats de verkregen informatie van Clarifai in een overzicht

Na het bevragen van de Clarifa API was er per beeld een API response in JSON met daarin onder meer de tags die aan de beelden gegeven werden. Om de gegevens te valideren, werden ze verzameld in een CSV met volgende velden: URL van het beeld, modelnaam en vervolgens de max. twintig tags die Clarifai geeft inclusief hun waarschijnlijkheidswaarde (1 veld per tag met waarschijnlijkheidswaarde). Ook hiervoor werd een script geschreven. `jq` werd gebruikt om de JSON in bash te kunnen parsen en de gewenste gegevens uit de JSON-files te halen en in een CSV te steken: [process_json.sh](../research/scripts/process_json.sh). Vervolgens werd via het `paste`-commando de CSV van de dataset (stap 2) en de CSV van de API responses samengevoegd tot één CSV. Er werd zo'n CSV-bestand gemaakt per gebruikt model.

Om de gegevens te kunnen valideren, werd de CSV vervolgens geïmporteerd in een Google Sheet bestand. Google Sheets geeft de mogelijkheid om via de functie `IMAGE($url)` de beelden in het overzicht te hebben, wat het eenvoudiger maakt om te valideren. Bovendien kan de sheet eenvoudig gedeeld worden en kunnen ze door meerdere tegelijkertijd bekeken en gebruikt worden.

## 5. Valideer de gegevens

Vervolgens moeten de gegevens gevalideerd worden. Er zijn hier voorlopig twee denkpistes voor:

* iemand (bij voorkeur meerdere mensen om de individuele foutenmarge te verkleinen) valideert ieder veld door aan te vinken welke gegevens correct zijn (komt de tag overeen met wat er op het beeld staat). Dit is een methode die gebruikt werd bij MoMu. Het nadeel is dat dit voor +/- 1400 gegevens x 20 tags gedaan moet worden.
* we definiëren zelf enkele tags die we verwachten te zien per thema (we houden hierbij wel rekening met de concepten die het model kent) en markeren deze via conditional formatting. Via ingebouwde Google Sheets functies (bv. `COUNTIF()`) kunnen we dan nagaan op welke foto de software het best scoort en het minst scoort. We kunnen hiermee ook patronen zien (een voorlopig te zien patroon is bijvoorbeeld dat de software huwelijk uit de eerste helf van de 20e eeuw minder goed herkent, omdat mensen dan vaak niet de typische trouwkledij droegen zoals we het nu kennen).

De resultaten uit de Google sheet [resultaten Huis van Alijn](https://docs.google.com/spreadsheets/d/1V98rrxMtBUEipE9B7mJFupd5Iw8YP4ItUpO6pz5wm5I/edit?usp=sharing). In deze Google Sheet werd ook een link naar de JSON-bestanden opgenomen. Optie 2 werd hiervoor al uitgetest, maar Huis van Alijn moet nog gecontacteerd worden om na te gaan welke trefwoorden zij verwachten per thema en of er een optie is dat iemand een (deel) manueel valideert.

Voor de eerste vastellingen, zowel over resultaten van Clarifai als over het gebruik ervan, zie [vastellingen](vaststellingen.md)